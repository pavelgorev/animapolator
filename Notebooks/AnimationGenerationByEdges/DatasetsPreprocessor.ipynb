{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba901cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb47f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.TextProcessing import get_description_from, get_text_parameters\n",
    "from modules.DataLoading import LabeledAnimationLoader, create_loaders\n",
    "from modules.PlotAnimation import plot_sample, plot_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b88edcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "transformed_size = 32\n",
    "dataset_root = 'D:\\AI\\Blender\\Renders'\n",
    "train_size = 4800\n",
    "validation_size = 6400-train_size\n",
    "batch_size = 16\n",
    "\n",
    "animation_limit = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ef6f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text tokenizer\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "all_samples = os.listdir(dataset_root)\n",
    "all_descriptions = [get_description_from(x) for x in all_samples]\n",
    "\n",
    "print(all_descriptions)\n",
    "\n",
    "padding_word, encode, count_of_words = get_text_parameters(tokenizer, all_descriptions)\n",
    "\n",
    "for i in range(4):\n",
    "    print(encode(all_descriptions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bca72c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data FROM RAW IMAGES\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize([transformed_size, transformed_size]), \n",
    "    transforms.ToTensor(), \n",
    "])\n",
    "\n",
    "data_set_raw = LabeledAnimationLoader(root=dataset_root, transform=transform, encode_fnc=encode, animation_limit=animation_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e426f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Preprocessed data\n",
    "data_set_raw.save('D:\\AI\\Datasets\\DatasetPreprocessed\\data_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48333c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data from file\n",
    "data_set = LabeledAnimationLoader(preprocessed_data_path = 'D:\\AI\\Datasets\\DatasetPreprocessed\\data_set')\n",
    "\n",
    "all_descriptions_old = all_descriptions.copy()\n",
    "all_descriptions = 0\n",
    "    \n",
    "print(all_descriptions_old)\n",
    "\n",
    "all_descriptions = data_set.get_descriptions()\n",
    "print(all_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552c0895",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = create_loaders(data_set, padding_word, batch_size, train_size, validation_size, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2907cc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display data loaders\n",
    "for n, samples in enumerate(train_loader):\n",
    "    #print(f\"{samples['reference'].size() = }\")\n",
    "    for i in range(batch_size):\n",
    "        print(i)\n",
    "        plot_sample(samples, i)\n",
    "\n",
    "for n, samples in enumerate(val_loader):\n",
    "    plot_samples(samples, validation_size)\n",
    "        \n",
    "#for n, samples in enumerate(val_loader):\n",
    "#    print(f\"{samples['reference'].size() = }\")\n",
    "#    for i in range(validation_size):\n",
    "#        print(i)\n",
    "#        plot_sample(samples, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d994677f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan",
   "language": "python",
   "name": "gan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
